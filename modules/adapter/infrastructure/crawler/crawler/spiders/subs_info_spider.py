import math
import re
import time

import numpy as np
import pandas as pd
from bs4 import BeautifulSoup
from pandas import DataFrame
from scrapy import Spider, Request
from scrapy.exceptions import CloseSpider
from selenium.webdriver.chrome.webdriver import WebDriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions
from selenium.webdriver.support.select import Select
from selenium.webdriver.support.wait import WebDriverWait

from modules.adapter.infrastructure.crawler.crawler.enum.subs_info_enum import (
    SubscriptionInfoEnum,
)
from modules.adapter.infrastructure.pypubsub.enum.subs_info_enum import (
    SubsInfoTopicEnum,
)
from modules.adapter.infrastructure.pypubsub.event_listener import event_listener_dict
from modules.adapter.infrastructure.pypubsub.event_observer import send_message
from modules.adapter.infrastructure.slack.slack_mixin import SlackMixin
from modules.adapter.infrastructure.sqlalchemy.entity.datalake.v1.subs_entity import (
    SubscriptionInfoEntity,
)
from modules.adapter.infrastructure.sqlalchemy.persistence.model.datalake.subscription_info_model import (
    SubscriptionInfoModel,
)
from modules.adapter.infrastructure.utils.log_helper import logger_

logger = logger_.getLogger(__name__)


class SubscriptionSpider(Spider, SlackMixin):
    name: str = "subscription_infos"
    custom_settings: dict = {
        "DOWNLOADER_MIDDLEWARES": {
            "modules.adapter.infrastructure.crawler.crawler.middlewares.SeleniumDownloaderMiddleware": 100
        }
    }
    start_ym: str = SubscriptionInfoEnum.START_YEAR_MONTH.value
    end_ym: str = SubscriptionInfoEnum.END_YEAR_MONTH.value
    scan_results: DataFrame | None = None
    subs_info_last_id_seq: int = 0

    def start_requests(self):
        SubscriptionSpider.subs_info_last_id_seq = self.subs_info_last_id_seq
        url = SubscriptionInfoEnum.APPLY_HOME_URL.value

        emoji = "üöÄ"
        self.send_slack_message(
            title=f"{emoji} [SubscriptionSpider] >>> Ï≤≠ÏïΩÌôà ÌÅ¨Î°§Îü¨ ÏàòÏßë Task",
            message=f"start_ym : {SubscriptionSpider.start_ym} \n "
            f"end_ym : {SubscriptionSpider.end_ym} \n "
            f"Crawler Start to {SubscriptionSpider.name}\n ",
        )

        yield Request(url=url)

    def browser_interaction_before_parsing(self, driver: WebDriver):
        self._set_date_select_box_event(
            start_date=SubscriptionSpider.start_ym,
            end_date=SubscriptionSpider.end_ym,
            driver=driver,
        )

        self.scan_apply_home(
            driver=driver, last_page=self._get_last_page(driver=driver)
        )

    def scan_apply_home(self, driver: WebDriver, last_page: int):
        for page in range(1, last_page + 1):
            df_result_html: DataFrame = self._get_lookup_html(driver=driver, page=page)
            df_main_content: DataFrame = self._get_lookup_contents_per_each_row(
                driver=driver, page=page
            )
            df_detail: DataFrame = self._get_house_detail_data(driver=driver, page=page)
            df_competition: DataFrame = self._get_competition_data(
                driver=driver, page=page
            )

            merged_df = self._join_df(
                df_result_html, df_detail, df_main_content, df_competition
            )

            if page == 1:
                SubscriptionSpider.scan_results = merged_df.copy()
            else:
                SubscriptionSpider.scan_results = pd.concat(
                    [SubscriptionSpider.scan_results, merged_df], axis=0, join="outer"
                )

            try:
                self._click_next_page(
                    driver=driver, current_page=page, last_page=last_page
                )
                time.sleep(2.5)
            except Exception:
                time.sleep(1)
                self._click_next_page(
                    driver=driver, current_page=page, last_page=last_page
                )
                time.sleep(2.5)

        SubscriptionSpider.scan_results["Î∞úÌëúÎÇ†Ïßú"] = pd.to_datetime(
            SubscriptionSpider.scan_results["ÎãπÏ≤®ÏûêÎ∞úÌëú ÏàúÏúºÎ°ú Ï†ïÎ†¨"]
        )

        # Î™®ÏßëÍ≥µÍ≥†Ïùº Í∏∞Ï§Ä ÏùºÏûêÎ≥Ñ ÌïÑÌÑ∞ÎßÅ ÌïÑÏöîÌïú Í≤ΩÏö∞ mask ÏÇ¨Ïö©
        # start = "{}-{}-{}".format(start_year, start_month, start_day)
        # end = "{}-{}-{}".format(end_year, end_month, end_day)
        # mask = (SubscriptionSpider.scan_results["Î™®ÏßëÍ≥µÍ≥†Ïùº"] >= start) & (SubscriptionSpider.scan_results["Î™®ÏßëÍ≥µÍ≥†Ïùº"] <= end)
        # SubscriptionSpider.scan_results = SubscriptionSpider.scan_results.loc[mask]

        if (
            SubscriptionSpider.scan_results is None
            or len(SubscriptionSpider.scan_results) == 0
        ):
            raise Exception("ÏïÑÎ¨¥ Îç∞Ïù¥ÌÑ∞ÎèÑ Î∂àÎü¨Ïò§ÏßÄ Î™ªÌï®")

        columns = {
            "ÎãπÏ≤®ÏûêÎ∞úÌëú ÏàúÏúºÎ°ú Ï†ïÎ†¨": "Î∞úÌëúÏùº",
            "Ï£ºÌÉùÎ™Ö ÏàúÏúºÎ°ú Ï†ïÎ†¨": "Ï£ºÌÉùÎ™Ö",
            "2ÏàúÏúÑ Ï≤≠ÏïΩÍ∏à": "Ï≤≠ÏïΩÍ∏à_2ÏàúÏúÑ",
            "1¬∑2ÏàúÏúÑ Í≤ΩÏüÅÎ•†": "Í≤ΩÏüÅÎ•†_1_2ÏàúÏúÑ",
            "ÏãúÍ≥µÏÇ¨": "Í±¥ÏÑ§ÏóÖÏ≤¥",
        }
        SubscriptionSpider.scan_results.rename(columns=columns, inplace=True)

        SubscriptionSpider.scan_results = self._clean_up_columns(
            SubscriptionSpider.scan_results
        )

        # UniqueÍ∞íÏóê NullÏ†úÍ±∞
        unique_keys = ["Î™®ÏßëÍ≥µÍ≥†Ïùº", "Î∞úÌëúÏùº", "Ï£ºÌÉùÎ™Ö", "Ï£ºÌÉùÌòï"]
        SubscriptionSpider.scan_results = self._remove_null_in_unique(
            SubscriptionSpider.scan_results, unique_keys
        )
        SubscriptionSpider.scan_results = SubscriptionSpider.scan_results.where(
            (pd.notnull(SubscriptionSpider.scan_results)), None
        )

        rename_columns = {
            "Ï£ºÌÉùÌòï": "area_type",
            "Í≥µÍ∏âÍ∏àÏï°(ÏµúÍ≥†Í∞Ä Í∏∞Ï§Ä)": "supply_price",
            "Ï≤≠ÏïΩÍ∏à_2ÏàúÏúÑ": "second_subs_amount",
            "Ï£ºÏÜå": "origin_address",
            "Í≥µÍ∏âÍ∑úÎ™®": "supply_household",
            "Î™®ÏßëÍ≥µÍ≥†Ï£ºÏÜå": "offer_notice_url",
            "ÏûÖÏ£ºÏòàÏ†ïÏõî": "move_in_date",
            "Í≥ÑÏïΩÏùº": "contract_date",
            "ÌôàÌéòÏù¥ÏßÄÏ£ºÏÜå": "hompage_url",
            "Ìï¥ÎãπÏßÄÏó≠_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï": "special_supply_date",
            "Í∏∞ÌÉÄÏßÄÏó≠_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï": "special_supply_etc_date",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï": "special_etc_gyeonggi_date",
            "Ìï¥ÎãπÏßÄÏó≠_1ÏàúÏúÑ_ÏùºÏ†ï": "first_supply_date",
            "Í∏∞ÌÉÄÏßÄÏó≠_1ÏàúÏúÑ_ÏùºÏ†ï": "first_supply_etc_date",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_1ÏàúÏúÑ_ÏùºÏ†ï": "first_etc_gyeonggi_date",
            "Ìï¥ÎãπÏßÄÏó≠_2ÏàúÏúÑ_ÏùºÏ†ï": "second_supply_date",
            "Í∏∞ÌÉÄÏßÄÏó≠_2ÏàúÏúÑ_ÏùºÏ†ï": "second_supply_etc_date",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_2ÏàúÏúÑ_ÏùºÏ†ï": "second_etc_gyeonggi_date",
            "Ï£ºÌÉùÍ≥µÍ∏âÎ©¥Ï†Å": "supply_area",
            "ÏßÄÏó≠": "region",
            "Ï£ºÌÉùÍµ¨Î∂Ñ": "housing_category",
            "Î∂ÑÏñë/ÏûÑÎåÄ": "rent_type",
            "Ï£ºÌÉùÎ™Ö": "name",
            "Í±¥ÏÑ§ÏóÖÏ≤¥": "construct_company",
            "Î¨∏ÏùòÏ≤ò": "contact",
            "Ï≤≠ÏïΩÍ∏∞Í∞Ñ ÏàúÏúºÎ°ú Ï†ïÎ†¨": "subscription_date",
            "Î™®ÏßëÍ≥µÍ≥†Ïùº": "offer_date",
            "Î∞úÌëúÏùº": "notice_winner_date",
            "ÌäπÎ≥ÑÍ≥µÍ∏âÏã†Ï≤≠ÌòÑÌô©": "special_supply_status",
            "Í≤ΩÏüÅÎ•†_1_2ÏàúÏúÑ": "cmptt_rank",
            "Îã§ÏûêÎÖÄ_Í∞ÄÍµ¨_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "multi_children_vol_etc_gyeonggi",
            "Îã§ÏûêÎÖÄ_Í∞ÄÍµ¨_Í∏∞ÌÉÄÏßÄÏó≠": "multi_children_vol_etc",
            "Îã§ÏûêÎÖÄ_Í∞ÄÍµ¨_Î∞∞Ï†ïÏÑ∏ÎåÄÏàò": "multi_children_household",
            "Îã§ÏûêÎÖÄ_Í∞ÄÍµ¨_Ìï¥ÎãπÏßÄÏó≠": "multi_children_vol",
            "Ïã†Ìòº_Î∂ÄÎ∂Ä_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "newlywed_vol_etc_gyeonggi",
            "Ïã†Ìòº_Î∂ÄÎ∂Ä_Í∏∞ÌÉÄÏßÄÏó≠": "newlywed_vol_etc",
            "Ïã†Ìòº_Î∂ÄÎ∂Ä_Î∞∞Ï†ïÏÑ∏ÎåÄÏàò": "newlywed_household",
            "Ïã†Ìòº_Î∂ÄÎ∂Ä_Ìï¥ÎãπÏßÄÏó≠": "newlywed_vol",
            "ÏÉùÏï†ÏµúÏ¥à_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "first_life_vol_etc_gyeonggi",
            "ÏÉùÏï†ÏµúÏ¥à_Í∏∞ÌÉÄÏßÄÏó≠": "first_life_vol_etc",
            "ÏÉùÏï†ÏµúÏ¥à_Î∞∞Ï†ïÏÑ∏ÎåÄÏàò": "first_life_household",
            "ÏÉùÏï†ÏµúÏ¥à_Ìï¥ÎãπÏßÄÏó≠": "first_life_vol",
            "ÎÖ∏Î∂ÄÎ™®_Î∂ÄÏñë_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "old_parent_vol_etc_gyeonggi",
            "ÎÖ∏Î∂ÄÎ™®_Î∂ÄÏñë_Í∏∞ÌÉÄÏßÄÏó≠": "old_parent_vol_etc",
            "ÎÖ∏Î∂ÄÎ™®_Î∂ÄÏñë_Î∞∞Ï†ïÏÑ∏ÎåÄÏàò": "old_parent_household",
            "ÎÖ∏Î∂ÄÎ™®_Î∂ÄÏñë_Ìï¥ÎãπÏßÄÏó≠": "old_parent_vol",
            "Í∏∞Í¥Ä_Ï∂îÏ≤ú_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "agency_recommend_etc_gyeonggi",
            "Í∏∞Í¥Ä_Ï∂îÏ≤ú_Í∏∞ÌÉÄÏßÄÏó≠": "agency_recommend_etc",
            "Í∏∞Í¥Ä_Ï∂îÏ≤ú_Î∞∞Ï†ïÏÑ∏ÎåÄÏàò": "agency_recommend_house_hold",
            "Í∏∞Í¥Ä_Ï∂îÏ≤ú_Ìï¥ÎãπÏßÄÏó≠": "agency_recommend_vol",
            "ÏùºÎ∞òÍ≥µÍ∏â_Ïã§Ïßà_Í≥µÍ∏âÏÑ∏ÎåÄÏàò": "official_general_household",
            "ÏùºÎ∞òÍ≥µÍ∏â_Í≥µÍ∏âÏÑ∏ÎåÄÏàò": "general_household",
            "ÌäπÎ≥ÑÍ≥µÍ∏â_Í≥µÍ∏âÏÑ∏ÎåÄÏàò": "special_household",
            "1ÏàúÏúÑÎãπÌï¥_Ï†ëÏàòÍ±¥Ïàò": "first_accept_cnt",
            "1ÏàúÏúÑÍ∏∞ÌÉÄ_Ï†ëÏàòÍ±¥Ïàò": "first_accept_cnt_etc",
            "1ÏàúÏúÑÍ≤ΩÍ∏∞_Ï†ëÏàòÍ±¥Ïàò": "first_accept_cnt_gyeonggi",
            "2ÏàúÏúÑÎãπÌï¥_Ï†ëÏàòÍ±¥Ïàò": "second_accept_cnt",
            "2ÏàúÏúÑÍ∏∞ÌÉÄ_Ï†ëÏàòÍ±¥Ïàò": "second_accept_cnt_etc",
            "2ÏàúÏúÑÍ≤ΩÍ∏∞_Ï†ëÏàòÍ±¥Ïàò": "second_accept_cnt_gyeonggi",
            "1ÏàúÏúÑÎãπÌï¥_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†": "first_cmptt_rate",
            "1ÏàúÏúÑÍ≤ΩÍ∏∞_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†": "first_cmptt_rate_gyeonggi",
            "1ÏàúÏúÑÍ∏∞ÌÉÄ_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†": "first_cmptt_rate_etc",
            "2ÏàúÏúÑÎãπÌï¥_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†": "second_cmptt_rate",
            "2ÏàúÏúÑÍ≤ΩÍ∏∞_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†": "second_cmptt_rate_gyeonggi",
            "2ÏàúÏúÑÍ∏∞ÌÉÄ_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†": "second_cmptt_rate_etc",
            "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä": "lowest_win_point_etc",
            "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä": "lowest_win_point",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä": "lowest_win_point_gyeonggi",
            "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†": "top_win_point_etc",
            "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†": "top_win_point",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†": "top_win_point_gyeonggi",
            "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†": "avg_win_point_etc",
            "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†": "avg_win_point",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†": "avg_win_point_gyeonggi",
            "subs_id": "subs_id",
        }
        SubscriptionSpider.scan_results.rename(columns=rename_columns, inplace=True)

        SubscriptionSpider.scan_results["name"] = SubscriptionSpider.scan_results[
            "name"
        ].str.replace("'", "")

    def parse(self, response, **kwargs):
        try:
            subs_info_dicts: list[dict] = self.convert_result_to_list()
            parsed_subs_info_models: list[SubscriptionInfoModel] = list()
            create_list: list[SubscriptionInfoModel] = list()
            update_list: list[SubscriptionInfoModel] = list()

            for subs_info_dict in subs_info_dicts:
                parsed_subs_info_models.append(SubscriptionInfoModel(**subs_info_dict))

            subs_infos_from_current_db: list[
                SubscriptionInfoEntity
            ] = self.__find_subs_infos_by_year_month()

            if subs_infos_from_current_db:
                for parsed_info in parsed_subs_info_models:
                    for subs_info in subs_infos_from_current_db:
                        if (
                            parsed_info.name == subs_info.name
                            and parsed_info.offer_date == subs_info.offer_date
                            and parsed_info.rent_type == subs_info.rent_type
                            and parsed_info.area_type == subs_info.area_type
                            and str(int(parsed_info.supply_price))
                            == subs_info.supply_price
                        ):
                            parsed_info.id = subs_info.id
                            update_list.append(parsed_info)

                if update_list:
                    for parsed_info in parsed_subs_info_models:
                        if parsed_info not in update_list:
                            create_list.append(parsed_info)
                else:
                    for parsed_info in parsed_subs_info_models:
                        create_list.append(parsed_info)
            else:
                for parsed_info in parsed_subs_info_models:
                    create_list.append(parsed_info)

            if create_list:
                self._save_subs_infos(subs_infos=create_list)

            if update_list:
                for elm in update_list:
                    self._update(elm)

            self.repo.update_id_to_code_rules(
                key_div="subs_id", last_id=SubscriptionSpider.subs_info_last_id_seq
            )

            emoji = "üöÄ"
            self.send_slack_message(
                title=f"{emoji} [SubscriptionSpider] >>> Ï≤≠ÏïΩÌôà ÌÅ¨Î°§Îü¨ ÏàòÏßë Finished",
                message=f"create_list : {len(create_list) if create_list else 0} \n "
                f"update_list : {len(update_list) if update_list else 0} \n ",
            )
        except Exception as e:
            emoji = "‚ò†Ô∏è"
            self.send_slack_message(
                title=f"{emoji} [SubscriptionSpider] >>> Ï≤≠ÏïΩÌôà ÌÅ¨Î°§Îü¨ ÏàòÏßë Finished",
                message=f"error - {e} \n ",
            )

    def convert_result_to_list(self) -> list[dict]:
        result_to_list: list = list()
        for idx, row in SubscriptionSpider.scan_results.iterrows():
            temp_dic = row.to_dict()
            temp_dic = {
                key: None if self._is_nan(val) else val for key, val in temp_dic.items()
            }
            result_to_list.append(temp_dic)

        return result_to_list

    def _set_date_select_box_event(
        self, start_date: str, end_date: str, driver: WebDriver
    ) -> None:
        select_start = Select(driver.find_element(By.CSS_SELECTOR, "#start_year"))
        select_start.select_by_visible_text(start_date)
        select_end = Select(driver.find_element(By.CSS_SELECTOR, "#end_year"))
        select_end.select_by_visible_text(end_date)
        driver.find_element(By.CSS_SELECTOR, ".search_btn").click()

    def _get_last_page(self, driver: WebDriver) -> int:
        total_txt_frame = driver.find_element(By.CLASS_NAME, "total_txt")
        total_txt_num = total_txt_frame.find_element(By.CLASS_NAME, "color_blue").text
        total_txt_num = int(total_txt_num)
        last_page = math.ceil(total_txt_num / 10)

        return last_page

    def _get_lookup_html(self, driver: WebDriver, page: int) -> DataFrame:
        inner_html: str = driver.page_source
        bs: BeautifulSoup = BeautifulSoup(inner_html, "html.parser")
        tags = bs.find("table", attrs={"class": "tbl_st"})

        df: DataFrame = pd.read_html(str(tags), header=0)[0]

        df = df.reset_index()
        df["index"] = df["index"] + (page - 1) * 10
        return df

    def _set_apt_type(self, data) -> str:
        if type(data) is float or type(data) is int or type(data) is np.float64:
            if data < 100:
                if data < 10:
                    result = "".join(["00", str(data)])
                else:
                    result = "".join(["0", str(data)])
            else:
                result = str(data)

            if len(result) == 7:
                return "".join([result, "0"])
            elif len(result) == 6:
                return "".join([result, "00"])
            elif len(result) == 5:
                return "".join([result, "000"])
            else:
                return result

        else:
            return str(data)

    def _get_data_innerhtml(self, driver: WebDriver) -> DataFrame:
        time.sleep(0.2)
        driver.switch_to.frame("iframeDialog")
        inner_html = driver.page_source
        bs: BeautifulSoup = BeautifulSoup(inner_html, "html.parser")
        try:
            tags = bs.find_all("table", attrs={"class": "tbl_st"})[0]
        except Exception:
            time.sleep(30)
            tags = bs.find_all("table", attrs={"class": "tbl_st"})[0]

        table: DataFrame = pd.read_html(str(tags))[0]

        driver.switch_to.parent_frame()
        return table

    def _get_lookup_contents_per_each_row(
        self, driver: WebDriver, page: int
    ) -> DataFrame | None:
        table = driver.find_element(By.CLASS_NAME, "tbl_st")
        tbody = table.find_element(By.TAG_NAME, "tbody")
        rows = tbody.find_elements(By.TAG_NAME, "tr")

        df_apply = pd.DataFrame()
        for i in range(len(rows)):
            try:
                body = rows[i].find_elements(By.TAG_NAME, "td")
            except Exception:
                time.sleep(1)
                driver.find_element(By.CLASS_NAME, "ui-button").click()
                body = rows[i].find_elements(By.TAG_NAME, "td")

            button_apply_stat = body[9].find_elements(By.TAG_NAME, "button")
            if len(button_apply_stat) > 0:
                button_apply_stat[0].click()
                time.sleep(2.5)
                try:
                    df_temp = self._get_data_innerhtml(driver=driver)
                except Exception:
                    time.sleep(2)
                    try:
                        button_apply_stat[0].click()
                        df_temp = self._get_data_innerhtml(driver=driver)
                    except Exception:
                        time.sleep(2)
                        df_temp = self._get_data_innerhtml(driver=driver)

                df_temp["index"] = int(i) + (page - 1) * 10

                if len(df_apply) == 0:
                    df_apply = df_temp.copy()
                else:
                    df_apply = pd.concat([df_apply, df_temp])

                driver.find_element(By.CLASS_NAME, "ui-button").click()

        if len(df_apply) == 0:
            return None

        df_apply = df_apply.sort_values("index")
        df_apply.columns = df_apply.columns.droplevel()

        columns = {
            "Í≥µÍ∏â ÏÑ∏ÎåÄÏàò": "ÌäπÎ≥ÑÍ≥µÍ∏â_Í≥µÍ∏âÏÑ∏ÎåÄÏàò",
            "Îã§ÏûêÎÖÄ Í∞ÄÍµ¨": "Îã§ÏûêÎÖÄ_Í∞ÄÍµ¨",
            "Ïã†Ìòº Î∂ÄÎ∂Ä": "Ïã†Ìòº_Î∂ÄÎ∂Ä",
            "ÎÖ∏Î∂ÄÎ™® Î∂ÄÏñë": "ÎÖ∏Î∂ÄÎ™®_Î∂ÄÏñë",
            "Í∏∞Í¥Ä Ï∂îÏ≤ú": "Í∏∞Í¥Ä_Ï∂îÏ≤ú",
            "": "index",
        }

        df_apply = df_apply.rename(columns=columns)

        df_apply = pd.pivot(
            df_apply,
            columns="ÏßÄÏó≠",
            values=["Îã§ÏûêÎÖÄ_Í∞ÄÍµ¨", "Ïã†Ìòº_Î∂ÄÎ∂Ä", "ÏÉùÏï†ÏµúÏ¥à", "ÎÖ∏Î∂ÄÎ™®_Î∂ÄÏñë", "Í∏∞Í¥Ä_Ï∂îÏ≤ú"],
            index=["index", "Ï£ºÌÉùÌòï", "ÌäπÎ≥ÑÍ≥µÍ∏â_Í≥µÍ∏âÏÑ∏ÎåÄÏàò"],
        )

        columns_level0 = list(df_apply.columns.droplevel(0))
        columns_level1 = list(df_apply.columns.droplevel(1))
        columns = [
            str(x) + "_" + str(y) for x, y in zip(columns_level1, columns_level0)
        ]
        df_apply.columns = columns
        df_apply = df_apply.reset_index()
        df_apply["Ï£ºÌÉùÌòï"] = df_apply["Ï£ºÌÉùÌòï"].apply(self._set_apt_type)

        return df_apply

    def _get_innerhtml_detail_data(self, driver: WebDriver) -> DataFrame:
        time.sleep(0.2)
        driver.switch_to.frame("iframeDialog")
        inner_html = driver.page_source
        bs: BeautifulSoup = BeautifulSoup(inner_html, "html.parser")

        table_detail_data = bs.find_all("table", attrs={"class": "tbl_st"})[0]
        address = table_detail_data.find_all("td", attrs={"class": "txt_l"})[0].text
        apt_num = table_detail_data.find_all("td", attrs={"class": "txt_l"})[1].text
        table_name_ls = bs.find_all("h5")

        # Í≥µÍ∏âÍ∏àÏï°
        num = 0
        for i in range(len(table_name_ls)):
            if "Í≥µÍ∏âÍ∏àÏï°" in table_name_ls[i].text:
                num = i

        tags = bs.find_all("table", attrs={"class": "tbl_st"})[num]
        table = pd.read_html(str(tags))[0]
        table["Ï£ºÏÜå"] = address
        table["Í≥µÍ∏âÍ∑úÎ™®"] = apt_num

        # Î™®ÏßëÍ≥µÍ≥† Ï£ºÏÜå
        try:
            url = bs.find_all("a", attrs={"class": "radius_btn"})[0]
            url = url.get_attribute_list("href")[0]
            apply_home_url = "https://www.applyhome.co.kr"
            url = "".join([apply_home_url, url])
            table["Î™®ÏßëÍ≥µÍ≥†Ï£ºÏÜå"] = url
        except Exception:
            table["Î™®ÏßëÍ≥µÍ≥†Ï£ºÏÜå"] = None

        # ÏûÖÏ£ºÏòàÏ†ïÏõî
        tags = bs.find_all("ul", attrs={"class": "inde_txt"})
        num = 0
        for i in range(len(tags)):
            if "ÏûÖÏ£ºÏòàÏ†ïÏõî" in tags[i].text:
                num = i

        text = tags[num].text
        match = re.search(r"\d{4}.\d{2}", text)
        table["ÏûÖÏ£ºÏòàÏ†ïÏõî"] = match.group()

        # Ï≤≠ÏïΩÏùºÏ†ï
        num = 0
        for i in range(len(table_name_ls)):
            if "Ï≤≠ÏïΩÏùºÏ†ï" in table_name_ls[i].text:
                num = i

        tags = bs.find_all("table", attrs={"class": "tbl_st"})[num]
        table_date = pd.read_html(str(tags), header=1)[0]
        table["Í≥ÑÏïΩÏùº"] = table_date[table_date["Ï≤≠ÏïΩÏ†ëÏàò"] == "Í≥ÑÏïΩÏùº"]["Íµ¨Î∂Ñ"].iloc[0]
        homepage_addr_str = table_date[table_date["Ï≤≠ÏïΩÏ†ëÏàò"] == "ÎãπÏ≤®Ïûê Î∞úÌëúÏùº"]["Íµ¨Î∂Ñ"].iloc[0]
        try:
            table["ÌôàÌéòÏù¥ÏßÄÏ£ºÏÜå"] = re.findall("\(([^)]+)", homepage_addr_str)[0].strip()
        except Exception:
            table["ÌôàÌéòÏù¥ÏßÄÏ£ºÏÜå"] = None
        table_date = table_date.loc[:2]

        try:
            table_date["Í∏∞ÌÉÄÍ≤ΩÍ∏∞"]
        except KeyError:
            table_date["Í∏∞ÌÉÄÍ≤ΩÍ∏∞"] = None
        table_date = table_date[["Íµ¨Î∂Ñ", "Ìï¥ÎãπÏßÄÏó≠", "Í∏∞ÌÉÄÏßÄÏó≠", "Í∏∞ÌÉÄÍ≤ΩÍ∏∞"]]

        try:
            idx = table_date[table_date["Íµ¨Î∂Ñ"] == "ÌäπÎ≥ÑÍ≥µÍ∏â"].index[0]
            value = table_date.iloc[idx]["Ìï¥ÎãπÏßÄÏó≠"]
            table["Ìï¥ÎãπÏßÄÏó≠_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï"] = value
        except IndexError:
            table["Ìï¥ÎãπÏßÄÏó≠_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï"] = None

        try:
            idx = table_date[table_date["Íµ¨Î∂Ñ"] == "ÌäπÎ≥ÑÍ≥µÍ∏â"].index[0]
            value = table_date.iloc[idx]["Í∏∞ÌÉÄÏßÄÏó≠"]
            table["Í∏∞ÌÉÄÏßÄÏó≠_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï"] = value
        except IndexError:
            table["Í∏∞ÌÉÄÏßÄÏó≠_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï"] = None

        try:
            idx = table_date[table_date["Íµ¨Î∂Ñ"] == "ÌäπÎ≥ÑÍ≥µÍ∏â"].index[0]
            value = table_date.iloc[idx]["Í∏∞ÌÉÄÍ≤ΩÍ∏∞"]
            table["Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï"] = value
        except IndexError:
            table["Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï"] = None

        idx = table_date[table_date["Íµ¨Î∂Ñ"] == "1ÏàúÏúÑ"].index[0]
        value = table_date.iloc[idx]["Ìï¥ÎãπÏßÄÏó≠"]
        table["Ìï¥ÎãπÏßÄÏó≠_1ÏàúÏúÑ_ÏùºÏ†ï"] = value

        idx = table_date[table_date["Íµ¨Î∂Ñ"] == "1ÏàúÏúÑ"].index[0]
        value = table_date.iloc[idx]["Í∏∞ÌÉÄÏßÄÏó≠"]
        table["Í∏∞ÌÉÄÏßÄÏó≠_1ÏàúÏúÑ_ÏùºÏ†ï"] = value

        idx = table_date[table_date["Íµ¨Î∂Ñ"] == "1ÏàúÏúÑ"].index[0]
        value = table_date.iloc[idx]["Í∏∞ÌÉÄÍ≤ΩÍ∏∞"]
        table["Í∏∞ÌÉÄÍ≤ΩÍ∏∞_1ÏàúÏúÑ_ÏùºÏ†ï"] = value

        idx = table_date[table_date["Íµ¨Î∂Ñ"] == "2ÏàúÏúÑ"].index[0]
        value = table_date.iloc[idx]["Ìï¥ÎãπÏßÄÏó≠"]
        table["Ìï¥ÎãπÏßÄÏó≠_2ÏàúÏúÑ_ÏùºÏ†ï"] = value

        idx = table_date[table_date["Íµ¨Î∂Ñ"] == "2ÏàúÏúÑ"].index[0]
        value = table_date.iloc[idx]["Í∏∞ÌÉÄÏßÄÏó≠"]
        table["Í∏∞ÌÉÄÏßÄÏó≠_2ÏàúÏúÑ_ÏùºÏ†ï"] = value

        idx = table_date[table_date["Íµ¨Î∂Ñ"] == "2ÏàúÏúÑ"].index[0]
        value = table_date.iloc[idx]["Í∏∞ÌÉÄÍ≤ΩÍ∏∞"]
        table["Í∏∞ÌÉÄÍ≤ΩÍ∏∞_2ÏàúÏúÑ_ÏùºÏ†ï"] = value

        # Í≥µÍ∏âÎåÄÏÉÅ
        num = 0
        for i in range(len(table_name_ls)):
            if "Í≥µÍ∏âÎåÄÏÉÅ" in table_name_ls[i].text:
                num = i
                break

        tags = bs.find_all("table", attrs={"class": "tbl_st"})[num]
        table_range = pd.read_html(str(tags), header=1)[0]
        table_range = table_range[["Ï£ºÌÉùÌòï", "Ï£ºÌÉùÍ≥µÍ∏âÎ©¥Ï†Å(Ï£ºÍ±∞Ï†ÑÏö©+Ï£ºÍ±∞Í≥µÏö©)", "ÏùºÎ∞ò"]].copy()
        columns = {"Ï£ºÌÉùÍ≥µÍ∏âÎ©¥Ï†Å(Ï£ºÍ±∞Ï†ÑÏö©+Ï£ºÍ±∞Í≥µÏö©)": "Ï£ºÌÉùÍ≥µÍ∏âÎ©¥Ï†Å", "ÏùºÎ∞ò": "ÏùºÎ∞òÍ≥µÍ∏â_Í≥µÍ∏âÏÑ∏ÎåÄÏàò"}
        table_range.rename(columns=columns, inplace=True)
        table_range = table_range.loc[: len(table_range) - 2]

        table["Ï£ºÌÉùÌòï"] = table["Ï£ºÌÉùÌòï"].apply(self._set_apt_type)

        table = pd.merge(table, table_range, how="left", on="Ï£ºÌÉùÌòï")

        driver.switch_to.parent_frame()

        return table

    def _get_house_detail_data(self, driver: WebDriver, page: int):
        """
        ÏßÄÏó≠, Î∂ÑÏñë Í∞ÄÍ≤© Ï†ïÎ≥¥ Î∂àÎü¨Ïò¥

        :param page: Ï≤≠ÏïΩÌôà Î∂ÑÏñë Îç∞Ïù¥ÌÑ∞ Í≤åÏãúÍ∏Ä ÌéòÏù¥ÏßÄ
        :return: DataFrame
        """
        table = driver.find_element(By.CLASS_NAME, "tbl_st")
        tbody = table.find_element(By.TAG_NAME, "tbody")
        rows = tbody.find_elements(By.TAG_NAME, "tr")

        df = pd.DataFrame()
        for i in range(len(rows)):
            try:
                body = rows[i].find_elements(By.TAG_NAME, "td")
                SubscriptionSpider.subs_info_last_id_seq = (
                    SubscriptionSpider.subs_info_last_id_seq + 1
                )
            except Exception:
                time.sleep(1)
                try:
                    driver.find_element(By.CLASS_NAME, "ui-button").click()
                except Exception:
                    driver.switch_to.parent_frame()
                    driver.find_element(By.CLASS_NAME, "ui-button").click()

                body = rows[i].find_elements(By.TAG_NAME, "td")

            button_detail_stat = body[3].find_elements(By.TAG_NAME, "a")[0]
            button_detail_stat.click()
            time.sleep(2.5)

            try:
                df_temp = self._get_innerhtml_detail_data(driver=driver)
            except Exception:
                try:
                    time.sleep(1)
                    button_detail_stat.click()
                    df_temp = self._get_innerhtml_detail_data(driver=driver)
                except Exception:
                    driver.switch_to.parent_frame()
                    driver.find_element(By.CLASS_NAME, "ui-button").click()
                    continue

            driver.find_element(By.CLASS_NAME, "ui-button").click()
            df_temp["index"] = int(i) + (page - 1) * 10
            df_temp["subs_id"] = SubscriptionSpider.subs_info_last_id_seq
            if len(df) == 0:
                df = df_temp.copy()
            else:
                df = pd.concat([df, df_temp])

        if len(df) == 0:
            return None
        else:
            df.reset_index(drop=True, inplace=True)
            return df

    def _get_innerhtml_competition_data(self, driver: WebDriver) -> DataFrame | None:
        try:
            time.sleep(0.2)
            driver.switch_to.frame("iframeDialog")
            inner_html = driver.page_source
            bs: BeautifulSoup = BeautifulSoup(inner_html, "html.parser")

            tags = bs.find_all("table", attrs={"class": "tbl_st"})[0]
            table = pd.read_html(str(tags))[0]
            columns = [
                "Ï£ºÌÉùÌòï",
                "ÏùºÎ∞òÍ≥µÍ∏â_Ïã§Ïßà_Í≥µÍ∏âÏÑ∏ÎåÄÏàò",
                "ÏàúÏúÑ",
                "ÏßÄÏó≠",
                "Ï†ëÏàòÍ±¥Ïàò",
                "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                "Ï≤≠ÏïΩÍ≤∞Í≥º",
                "ÎãπÏ≤®Í∞ÄÏ†ê_ÏßÄÏó≠",
                "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÏ†Ä",
                "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÍ≥†",
                "ÎãπÏ≤®Í∞ÄÏ†ê_ÌèâÍ∑†",
            ]
            table.columns = columns
        except Exception:
            driver.switch_to.parent_frame()
            return None

        table["Ï£ºÌÉùÌòï"] = table["Ï£ºÌÉùÌòï"].apply(self._set_apt_type)
        driver.switch_to.parent_frame()

        return table

    def _get_competition_data(self, driver: WebDriver, page: int) -> DataFrame | None:
        """
        Ï≤≠ÏïΩÌôà ÏùºÎ∞òÎ∂ÑÏñë Í≤ΩÏüÅÎ•† Îç∞Ïù¥ÌÑ∞ ÌÅ¨Î°§ÎßÅÌï®
        :return: DataFrame
        """

        table = WebDriverWait(driver, 10).until(
            expected_conditions.presence_of_element_located((By.CLASS_NAME, "tbl_st"))
        )
        tbody = table.find_element(By.TAG_NAME, "tbody")
        rows = tbody.find_elements(By.TAG_NAME, "tr")

        df = pd.DataFrame()
        for i in range(len(rows)):
            try:
                body = rows[i].find_elements(By.TAG_NAME, "td")
            except Exception:
                time.sleep(1)
                driver.find_element(By.CLASS_NAME, "ui-button").click()
                body = rows[i].find_elements(By.TAG_NAME, "td")

            button_detail_stat = body[10]
            if button_detail_stat.text == "ÏÇ¨ÏóÖÏ£ºÏ≤¥Î¨∏Ïùò":
                continue

            button_detail_stat.click()
            time.sleep(2.5)
            try:
                df_temp = self._get_innerhtml_competition_data(driver=driver)
            except Exception:
                time.sleep(1)
                button_detail_stat.click()
                df_temp = self._get_innerhtml_competition_data(driver=driver)

            try:
                driver.find_element(By.CLASS_NAME, "ui-button").click()
            except Exception:
                button_detail_stat.click()
                time.sleep(2.5)
                df_temp = self._get_innerhtml_competition_data(driver=driver)
                driver.find_element(By.CLASS_NAME, "ui-button").click()

            if df_temp is None:
                continue
            else:
                df_temp["index"] = int(i) + (page - 1) * 10

            if len(df) == 0:
                df = df_temp.copy()
            else:
                df = pd.concat([df, df_temp])

        df.reset_index(drop=True, inplace=True)
        if len(df) == 0:
            return None

        pivot_df1 = pd.pivot(
            df,
            columns=["ÏàúÏúÑ", "ÏßÄÏó≠"],
            values=["Ï†ëÏàòÍ±¥Ïàò", "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†"],
            index=["Ï£ºÌÉùÌòï", "index", "ÏùºÎ∞òÍ≥µÍ∏â_Ïã§Ïßà_Í≥µÍ∏âÏÑ∏ÎåÄÏàò"],
        )

        try:
            drop_col = [("Ï†ëÏàòÍ±¥Ïàò", "ÏàúÏúÑ", np.nan), ("ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†", "ÏàúÏúÑ", np.nan)]
            pivot_df1.drop(columns=drop_col, inplace=True)
        except Exception:
            pass

        if len(pivot_df1.columns) == 8:
            pivot_df1.columns = ["_".join(str(col)) for col in pivot_df1.columns.values]
            pivot_df1.rename(
                columns={
                    "Ï†ëÏàòÍ±¥Ïàò_1ÏàúÏúÑ_Ìï¥ÎãπÏßÄÏó≠": "1ÏàúÏúÑÎãπÌï¥_Ï†ëÏàòÍ±¥Ïàò",
                    "Ï†ëÏàòÍ±¥Ïàò_1ÏàúÏúÑ_Í∏∞ÌÉÄÏßÄÏó≠": "1ÏàúÏúÑÍ∏∞ÌÉÄ_Ï†ëÏàòÍ±¥Ïàò",
                    "Ï†ëÏàòÍ±¥Ïàò_2ÏàúÏúÑ_Ìï¥ÎãπÏßÄÏó≠": "2ÏàúÏúÑÎãπÌï¥_Ï†ëÏàòÍ±¥Ïàò",
                    "Ï†ëÏàòÍ±¥Ïàò_2ÏàúÏúÑ_Í∏∞ÌÉÄÏßÄÏó≠": "2ÏàúÏúÑÍ∏∞ÌÉÄ_Ï†ëÏàòÍ±¥Ïàò",
                    "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†_1ÏàúÏúÑ_Ìï¥ÎãπÏßÄÏó≠": "1ÏàúÏúÑÎãπÌï¥_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                    "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†_1ÏàúÏúÑ_Í∏∞ÌÉÄÏßÄÏó≠": "1ÏàúÏúÑÍ∏∞ÌÉÄ_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                    "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†_2ÏàúÏúÑ_Ìï¥ÎãπÏßÄÏó≠": "2ÏàúÏúÑÎãπÌï¥_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                    "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†_2ÏàúÏúÑ_Í∏∞ÌÉÄÏßÄÏó≠": "2ÏàúÏúÑÍ∏∞ÌÉÄ_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                },
                inplace=True,
            )
            pivot_df1["1ÏàúÏúÑÍ≤ΩÍ∏∞_Ï†ëÏàòÍ±¥Ïàò"] = None
            pivot_df1["2ÏàúÏúÑÍ≤ΩÍ∏∞_Ï†ëÏàòÍ±¥Ïàò"] = None
            pivot_df1["1ÏàúÏúÑÍ≤ΩÍ∏∞_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†"] = None
            pivot_df1["2ÏàúÏúÑÍ≤ΩÍ∏∞_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†"] = None

        else:
            pivot_df1.columns = ["_".join(str(col)) for col in pivot_df1.columns.values]
            pivot_df1.rename(
                columns={
                    "Ï†ëÏàòÍ±¥Ïàò_1ÏàúÏúÑ_Ìï¥ÎãπÏßÄÏó≠": "1ÏàúÏúÑÎãπÌï¥_Ï†ëÏàòÍ±¥Ïàò",
                    "Ï†ëÏàòÍ±¥Ïàò_1ÏàúÏúÑ_Í∏∞ÌÉÄÏßÄÏó≠": "1ÏàúÏúÑÍ∏∞ÌÉÄ_Ï†ëÏàòÍ±¥Ïàò",
                    "Ï†ëÏàòÍ±¥Ïàò_2ÏàúÏúÑ_Ìï¥ÎãπÏßÄÏó≠": "2ÏàúÏúÑÎãπÌï¥_Ï†ëÏàòÍ±¥Ïàò",
                    "Ï†ëÏàòÍ±¥Ïàò_2ÏàúÏúÑ_Í∏∞ÌÉÄÏßÄÏó≠": "2ÏàúÏúÑÍ∏∞ÌÉÄ_Ï†ëÏàòÍ±¥Ïàò",
                    "Ï†ëÏàòÍ±¥Ïàò_1ÏàúÏúÑ_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "1ÏàúÏúÑÍ≤ΩÍ∏∞_Ï†ëÏàòÍ±¥Ïàò",
                    "Ï†ëÏàòÍ±¥Ïàò_2ÏàúÏúÑ_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "2ÏàúÏúÑÍ≤ΩÍ∏∞_Ï†ëÏàòÍ±¥Ïàò",
                    "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†_1ÏàúÏúÑ_Ìï¥ÎãπÏßÄÏó≠": "1ÏàúÏúÑÎãπÌï¥_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                    "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†_1ÏàúÏúÑ_Í∏∞ÌÉÄÏßÄÏó≠": "1ÏàúÏúÑÍ∏∞ÌÉÄ_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                    "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†_2ÏàúÏúÑ_Ìï¥ÎãπÏßÄÏó≠": "2ÏàúÏúÑÎãπÌï¥_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                    "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†_2ÏàúÏúÑ_Í∏∞ÌÉÄÏßÄÏó≠": "2ÏàúÏúÑÍ∏∞ÌÉÄ_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                    "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†_1ÏàúÏúÑ_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "1ÏàúÏúÑÍ≤ΩÍ∏∞_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                    "ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†_2ÏàúÏúÑ_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "2ÏàúÏúÑÍ≤ΩÍ∏∞_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
                },
                inplace=True,
            )

        df_point = df[
            [
                "Ï£ºÌÉùÌòï",
                "index",
                "ÏùºÎ∞òÍ≥µÍ∏â_Ïã§Ïßà_Í≥µÍ∏âÏÑ∏ÎåÄÏàò",
                "ÎãπÏ≤®Í∞ÄÏ†ê_ÏßÄÏó≠",
                "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÏ†Ä",
                "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÍ≥†",
                "ÎãπÏ≤®Í∞ÄÏ†ê_ÌèâÍ∑†",
            ]
        ]
        df_point = df_point[df_point["ÎãπÏ≤®Í∞ÄÏ†ê_ÏßÄÏó≠"].isin(["Ìï¥ÎãπÏßÄÏó≠", "Í∏∞ÌÉÄÍ≤ΩÍ∏∞", "Í∏∞ÌÉÄÏßÄÏó≠"])]
        df_point = df_point.groupby(["Ï£ºÌÉùÌòï", "index", "ÎãπÏ≤®Í∞ÄÏ†ê_ÏßÄÏó≠"]).first()
        df_point.reset_index(drop=False, inplace=True)

        pivot_df2 = pd.pivot(
            df_point,
            columns="ÎãπÏ≤®Í∞ÄÏ†ê_ÏßÄÏó≠",
            values=["ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÏ†Ä", "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÍ≥†", "ÎãπÏ≤®Í∞ÄÏ†ê_ÌèâÍ∑†"],
            index=["Ï£ºÌÉùÌòï", "index", "ÏùºÎ∞òÍ≥µÍ∏â_Ïã§Ïßà_Í≥µÍ∏âÏÑ∏ÎåÄÏàò"],
        )

        if len(pivot_df2.columns) == 6:
            pivot_df2.columns = ["_".join(col) for col in pivot_df2.columns.values]
            pivot_df2.rename(
                columns={
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÏ†Ä_Í∏∞ÌÉÄÏßÄÏó≠": "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÏ†Ä_Ìï¥ÎãπÏßÄÏó≠": "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÍ≥†_Í∏∞ÌÉÄÏßÄÏó≠": "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÍ≥†_Ìï¥ÎãπÏßÄÏó≠": "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÌèâÍ∑†_Í∏∞ÌÉÄÏßÄÏó≠": "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÌèâÍ∑†_Ìï¥ÎãπÏßÄÏó≠": "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†",
                },
                inplace=True,
            )
            pivot_df2["Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä"] = None
            pivot_df2["Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†"] = None
            pivot_df2["Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†"] = None

        elif len(pivot_df2.columns) == 9:
            pivot_df2.columns = ["_".join(col) for col in pivot_df2.columns.values]
            pivot_df2.rename(
                columns={
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÏ†Ä_Í∏∞ÌÉÄÏßÄÏó≠": "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÏ†Ä_Ìï¥ÎãπÏßÄÏó≠": "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÍ≥†_Í∏∞ÌÉÄÏßÄÏó≠": "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÍ≥†_Ìï¥ÎãπÏßÄÏó≠": "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÌèâÍ∑†_Í∏∞ÌÉÄÏßÄÏó≠": "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÌèâÍ∑†_Ìï¥ÎãπÏßÄÏó≠": "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÏ†Ä_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÍ≥†_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÌèâÍ∑†_Í∏∞ÌÉÄÍ≤ΩÍ∏∞": "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†",
                },
                inplace=True,
            )

        elif len(pivot_df2.columns) == 3:
            pivot_df2.columns = ["Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä", "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†", "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†"]

            pivot_df2.columns = ["_".join(str(col)) for col in pivot_df2.columns.values]
            pivot_df2.rename(
                columns={
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÏ†Ä_Ìï¥ÎãπÏßÄÏó≠": "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÏµúÍ≥†_Ìï¥ÎãπÏßÄÏó≠": "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†",
                    "ÎãπÏ≤®Í∞ÄÏ†ê_ÌèâÍ∑†_Ìï¥ÎãπÏßÄÏó≠": "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†",
                },
                inplace=True,
            )

            pivot_df2["Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä"] = None
            pivot_df2["Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†"] = None
            pivot_df2["Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†"] = None

            pivot_df2["Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä"] = None
            pivot_df2["Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†"] = None
            pivot_df2["Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†"] = None

        elif len(pivot_df2.columns) == 0:
            pivot_df2 = None
        else:
            raise Exception("competition error")

        if pivot_df2 is None:
            df_result = pivot_df1.copy()
            df_result.reset_index(inplace=True)
        else:
            df_result = pd.merge(
                pivot_df1, pivot_df2, how="outer", left_index=True, right_index=True
            )
            df_result.reset_index(inplace=True)

        if len(df_result) == 0:
            return None
        else:
            return df_result

    def _join_df(
        self,
        df_data: DataFrame,
        df_detail: DataFrame,
        df_apply: DataFrame,
        df_competition: DataFrame,
    ) -> DataFrame:
        if df_detail is None:
            merged_df = df_data.copy()
        else:
            merged_df = pd.merge(
                df_detail, df_data, how="outer", left_on="index", right_on="index"
            )

        if df_apply is None:
            pass
        else:
            try:
                merged_df = pd.merge(
                    merged_df, df_apply, how="outer", on=["index", "Ï£ºÌÉùÌòï"]
                )
            except Exception:
                if df_detail is None:
                    merged_df = pd.merge(merged_df, df_apply, how="outer", on=["index"])
                else:
                    pass

        if df_competition is None:
            pass
        else:
            try:
                merged_df = pd.merge(
                    merged_df, df_competition, how="outer", on=["index", "Ï£ºÌÉùÌòï"]
                )
            except Exception:
                pass

        return merged_df

    def _is_nan(self, data) -> bool:
        try:
            return np.isnan(data)
        except Exception:
            return False

    def _click_next_page(self, driver: WebDriver, current_page: int, last_page: int):
        next_page = current_page + 1
        if int(current_page) == int(last_page):
            return
        script = "fn_link_page(" + str(next_page) + ");return false;"
        driver.execute_script(script)

    def _remove_null_in_unique(self, df: DataFrame, unique_columns) -> DataFrame:
        for col in unique_columns:
            df = df[df[col].notnull()]
        return df

    def _clean_up_columns(self, df: DataFrame) -> DataFrame:
        result_columns = [
            "Ï£ºÌÉùÌòï",
            "Í≥µÍ∏âÍ∏àÏï°(ÏµúÍ≥†Í∞Ä Í∏∞Ï§Ä)",
            "Ï≤≠ÏïΩÍ∏à_2ÏàúÏúÑ",
            "Ï£ºÏÜå",
            "Í≥µÍ∏âÍ∑úÎ™®",
            "Î™®ÏßëÍ≥µÍ≥†Ï£ºÏÜå",
            "ÏûÖÏ£ºÏòàÏ†ïÏõî",
            "Í≥ÑÏïΩÏùº",
            "ÌôàÌéòÏù¥ÏßÄÏ£ºÏÜå",
            "Ìï¥ÎãπÏßÄÏó≠_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï",
            "Í∏∞ÌÉÄÏßÄÏó≠_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÌäπÎ≥ÑÍ≥µÍ∏â_ÏùºÏ†ï",
            "Ìï¥ÎãπÏßÄÏó≠_1ÏàúÏúÑ_ÏùºÏ†ï",
            "Í∏∞ÌÉÄÏßÄÏó≠_1ÏàúÏúÑ_ÏùºÏ†ï",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_1ÏàúÏúÑ_ÏùºÏ†ï",
            "Ìï¥ÎãπÏßÄÏó≠_2ÏàúÏúÑ_ÏùºÏ†ï",
            "Í∏∞ÌÉÄÏßÄÏó≠_2ÏàúÏúÑ_ÏùºÏ†ï",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_2ÏàúÏúÑ_ÏùºÏ†ï",
            "Ï£ºÌÉùÍ≥µÍ∏âÎ©¥Ï†Å",
            "ÏßÄÏó≠",
            "Ï£ºÌÉùÍµ¨Î∂Ñ",
            "Î∂ÑÏñë/ÏûÑÎåÄ",
            "Ï£ºÌÉùÎ™Ö",
            "Í±¥ÏÑ§ÏóÖÏ≤¥",
            "Î¨∏ÏùòÏ≤ò",
            "Î™®ÏßëÍ≥µÍ≥†Ïùº",
            "Ï≤≠ÏïΩÍ∏∞Í∞Ñ ÏàúÏúºÎ°ú Ï†ïÎ†¨",
            "Î∞úÌëúÏùº",
            "ÌäπÎ≥ÑÍ≥µÍ∏âÏã†Ï≤≠ÌòÑÌô©",
            "Í≤ΩÏüÅÎ•†_1_2ÏàúÏúÑ",
            "Îã§ÏûêÎÖÄ_Í∞ÄÍµ¨_Í∏∞ÌÉÄÍ≤ΩÍ∏∞",
            "Îã§ÏûêÎÖÄ_Í∞ÄÍµ¨_Í∏∞ÌÉÄÏßÄÏó≠",
            "Îã§ÏûêÎÖÄ_Í∞ÄÍµ¨_Î∞∞Ï†ïÏÑ∏ÎåÄÏàò",
            "Îã§ÏûêÎÖÄ_Í∞ÄÍµ¨_Ìï¥ÎãπÏßÄÏó≠",
            "Ïã†Ìòº_Î∂ÄÎ∂Ä_Í∏∞ÌÉÄÍ≤ΩÍ∏∞",
            "Ïã†Ìòº_Î∂ÄÎ∂Ä_Í∏∞ÌÉÄÏßÄÏó≠",
            "Ïã†Ìòº_Î∂ÄÎ∂Ä_Î∞∞Ï†ïÏÑ∏ÎåÄÏàò",
            "Ïã†Ìòº_Î∂ÄÎ∂Ä_Ìï¥ÎãπÏßÄÏó≠",
            "ÏÉùÏï†ÏµúÏ¥à_Í∏∞ÌÉÄÍ≤ΩÍ∏∞",
            "ÏÉùÏï†ÏµúÏ¥à_Í∏∞ÌÉÄÏßÄÏó≠",
            "ÏÉùÏï†ÏµúÏ¥à_Î∞∞Ï†ïÏÑ∏ÎåÄÏàò",
            "ÏÉùÏï†ÏµúÏ¥à_Ìï¥ÎãπÏßÄÏó≠",
            "ÎÖ∏Î∂ÄÎ™®_Î∂ÄÏñë_Í∏∞ÌÉÄÍ≤ΩÍ∏∞",
            "ÎÖ∏Î∂ÄÎ™®_Î∂ÄÏñë_Í∏∞ÌÉÄÏßÄÏó≠",
            "ÎÖ∏Î∂ÄÎ™®_Î∂ÄÏñë_Î∞∞Ï†ïÏÑ∏ÎåÄÏàò",
            "ÎÖ∏Î∂ÄÎ™®_Î∂ÄÏñë_Ìï¥ÎãπÏßÄÏó≠",
            "Í∏∞Í¥Ä_Ï∂îÏ≤ú_Í∏∞ÌÉÄÍ≤ΩÍ∏∞",
            "Í∏∞Í¥Ä_Ï∂îÏ≤ú_Í∏∞ÌÉÄÏßÄÏó≠",
            "Í∏∞Í¥Ä_Ï∂îÏ≤ú_Î∞∞Ï†ïÏÑ∏ÎåÄÏàò",
            "Í∏∞Í¥Ä_Ï∂îÏ≤ú_Ìï¥ÎãπÏßÄÏó≠",
            "ÏùºÎ∞òÍ≥µÍ∏â_Ïã§Ïßà_Í≥µÍ∏âÏÑ∏ÎåÄÏàò",
            "ÏùºÎ∞òÍ≥µÍ∏â_Í≥µÍ∏âÏÑ∏ÎåÄÏàò",
            "ÌäπÎ≥ÑÍ≥µÍ∏â_Í≥µÍ∏âÏÑ∏ÎåÄÏàò",
            "1ÏàúÏúÑÎãπÌï¥_Ï†ëÏàòÍ±¥Ïàò",
            "1ÏàúÏúÑÍ∏∞ÌÉÄ_Ï†ëÏàòÍ±¥Ïàò",
            "1ÏàúÏúÑÍ≤ΩÍ∏∞_Ï†ëÏàòÍ±¥Ïàò",
            "2ÏàúÏúÑÎãπÌï¥_Ï†ëÏàòÍ±¥Ïàò",
            "2ÏàúÏúÑÍ∏∞ÌÉÄ_Ï†ëÏàòÍ±¥Ïàò",
            "2ÏàúÏúÑÍ≤ΩÍ∏∞_Ï†ëÏàòÍ±¥Ïàò",
            "1ÏàúÏúÑÎãπÌï¥_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
            "1ÏàúÏúÑÍ∏∞ÌÉÄ_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
            "1ÏàúÏúÑÍ≤ΩÍ∏∞_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
            "2ÏàúÏúÑÎãπÌï¥_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
            "2ÏàúÏúÑÍ∏∞ÌÉÄ_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
            "2ÏàúÏúÑÍ≤ΩÍ∏∞_ÏàúÏúÑÎÇ¥Í≤ΩÏüÅÎ•†",
            "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä",
            "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÏµúÏ†Ä",
            "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†",
            "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÏµúÍ≥†",
            "Í∏∞ÌÉÄÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†",
            "Ìï¥ÎãπÏßÄÏó≠_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†",
            "Í∏∞ÌÉÄÍ≤ΩÍ∏∞_ÎãπÏ≤®Í∞ÄÏ†êÌèâÍ∑†",
            "subs_id",
        ]
        for item in result_columns:
            if item not in df.columns:
                df[item] = None
        df = df[result_columns]
        return df

    def _save_subs_infos(self, subs_infos: list[SubscriptionInfoModel]):
        if subs_infos:
            self.__save_all(subs_infos=subs_infos)

    def _update(self, subs_info: SubscriptionInfoModel):
        if subs_info:
            self.__update_subs_info(subs_info=subs_info)

    def _trans_date_format(self, year_month: str):
        return year_month.replace("ÎÖÑ ", "-").replace("Ïõî", "")

    def __save_all(self, subs_infos: list[SubscriptionInfoModel]) -> None:
        send_message(
            topic_name=SubsInfoTopicEnum.SAVE_ALL.value,
            values=subs_infos,
        )
        return event_listener_dict.get(f"{SubsInfoTopicEnum.SAVE_ALL.value}")

    def __update_subs_info(self, subs_info: SubscriptionInfoModel) -> None:
        send_message(
            topic_name=SubsInfoTopicEnum.UPDATE_TO_NEW_SCHEMA.value,
            subs_info=subs_info,
        )
        return event_listener_dict.get(
            f"{SubsInfoTopicEnum.UPDATE_TO_NEW_SCHEMA.value}"
        )

    def __find_subs_infos_by_year_month(self) -> list[SubscriptionInfoEntity]:
        start_year_month = self._trans_date_format(
            year_month=SubscriptionSpider.start_ym
        )
        end_year_month = self._trans_date_format(year_month=SubscriptionSpider.end_ym)

        send_message(
            topic_name=SubsInfoTopicEnum.FIND_SUBSCRIPTION_INFOS_BY_YEAR_MONTH.value,
            start_year_month=start_year_month,
            end_year_month=end_year_month,
        )
        return event_listener_dict.get(
            f"{SubsInfoTopicEnum.FIND_SUBSCRIPTION_INFOS_BY_YEAR_MONTH.value}"
        )
